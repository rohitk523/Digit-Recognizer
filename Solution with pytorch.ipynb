{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import all the necessary libraries, frameworks and modules\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, TensorDataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-02T19:48:09.579977Z","iopub.execute_input":"2024-01-02T19:48:09.580704Z","iopub.status.idle":"2024-01-02T19:48:09.585897Z","shell.execute_reply.started":"2024-01-02T19:48:09.580672Z","shell.execute_reply":"2024-01-02T19:48:09.584939Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"# Instantiate the model and move it to the appropriate device (CPU or GPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-01-02T19:48:11.599986Z","iopub.execute_input":"2024-01-02T19:48:11.600357Z","iopub.status.idle":"2024-01-02T19:48:11.605291Z","shell.execute_reply.started":"2024-01-02T19:48:11.600325Z","shell.execute_reply":"2024-01-02T19:48:11.604165Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# Import the dataframes\ntrain_df = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest_df = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-02T19:48:13.158438Z","iopub.execute_input":"2024-01-02T19:48:13.159221Z","iopub.status.idle":"2024-01-02T19:48:17.297278Z","shell.execute_reply.started":"2024-01-02T19:48:13.159169Z","shell.execute_reply":"2024-01-02T19:48:17.296438Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# Normalize and reshape the training data\nX_train = train_df.iloc[:, 1:].values.reshape(-1, 1, 28, 28) / 255.0\ny_train = train_df.iloc[:, 0].values\n\n# Convert to PyTorch tensors\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train, dtype=torch.int64)\n\n# Create DataLoader for the training data\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n\n# Normalize and reshape the test data\nX_test = test_df.values.reshape(-1, 1, 28, 28) / 255.0\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n\n# Create DataLoader for the test data\ntest_loader = DataLoader(X_test_tensor, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T19:48:19.892810Z","iopub.execute_input":"2024-01-02T19:48:19.893676Z","iopub.status.idle":"2024-01-02T19:48:20.172561Z","shell.execute_reply.started":"2024-01-02T19:48:19.893644Z","shell.execute_reply":"2024-01-02T19:48:20.171565Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"# Define transformations\ntrain_transforms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, images, labels=None, transforms=None):\n        self.X = images\n        self.y = labels\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, i):\n        # Convert numpy array to PIL Image\n        data = Image.fromarray((self.X[i] * 255).astype(np.uint8).squeeze(), mode='L')\n        \n        if self.transforms:\n            data = self.transforms(data)\n        \n        if self.y is not None:\n            return data, self.y[i]\n        else:\n            return data\n\n# Apply transformations to the training dataset\ntrain_dataset = CustomDataset(X_train, y_train, train_transforms)\n\n# DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T19:48:22.876079Z","iopub.execute_input":"2024-01-02T19:48:22.876804Z","iopub.status.idle":"2024-01-02T19:48:22.885872Z","shell.execute_reply.started":"2024-01-02T19:48:22.876771Z","shell.execute_reply":"2024-01-02T19:48:22.884958Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"class DigitRecognizerCNN(nn.Module):\n    def __init__(self):\n        super(DigitRecognizerCNN, self).__init__()\n\n        # Convolutional layers\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(128)\n        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm2d(256)\n        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n        self.bn4 = nn.BatchNorm2d(512)\n\n        # Max pooling layer\n        self.pool = nn.MaxPool2d(2, 2)\n\n        # Dropout layers\n        self.dropout1 = nn.Dropout(0.3)\n        self.dropout2 = nn.Dropout(0.6)\n\n        # Fully connected layers\n        # Adjusting the size for the first fully connected layer\n        self.fc1 = nn.Linear(512 * 3 * 3, 1024)  # Adjusted size\n        self.fc2 = nn.Linear(1024, 512)\n        self.fc3 = nn.Linear(512, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n        x = F.relu(self.bn4(self.conv4(x)))  # No pooling here to maintain feature map size\n\n        # Flatten the output for the fully connected layer\n        x = x.view(-1, 512 * 3 * 3)  # Adjusted size\n\n        x = self.dropout1(x)\n        x = F.relu(self.fc1(x))\n        x = self.dropout2(x)\n        x = F.relu(self.fc2(x))  # Added missing ReLU\n        x = self.fc3(x)\n\n        return x\n\nmodel = DigitRecognizerCNN().to(device)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T19:48:28.621525Z","iopub.execute_input":"2024-01-02T19:48:28.621862Z","iopub.status.idle":"2024-01-02T19:48:28.686637Z","shell.execute_reply.started":"2024-01-02T19:48:28.621836Z","shell.execute_reply":"2024-01-02T19:48:28.685882Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"# Loss Function\nloss_fn = nn.CrossEntropyLoss()\n\n# Optimizer\noptimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n\n# Learning Rate Scheduler\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T19:48:31.983756Z","iopub.execute_input":"2024-01-02T19:48:31.984500Z","iopub.status.idle":"2024-01-02T19:48:31.989677Z","shell.execute_reply.started":"2024-01-02T19:48:31.984468Z","shell.execute_reply":"2024-01-02T19:48:31.988650Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"def train(dataloader, model, loss_fn, optimizer, device, epoch):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n\n        # Compute prediction and loss\n        pred = model(X)\n        loss = loss_fn(pred, y)\n        running_loss += loss.item()\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Calculate accuracy\n        _, predicted = torch.max(pred, 1)\n        total += y.size(0)\n        correct += (predicted == y).sum().item()\n\n        # Print statistics every 100 batches\n        if batch % 100 == 0:\n            loss_batch = running_loss / (batch + 1)\n            acc_batch = 100 * correct / total\n            print(f\"[{epoch + 1}, {batch + 1:5d}] loss: {loss_batch:.4f}, Accuracy: {acc_batch:.2f}%\")\n\n    # Print statistics at the end of the epoch\n    epoch_loss = running_loss / num_batches\n    epoch_acc = 100 * correct / size\n    print(f\"End of Epoch {epoch + 1}: Avg loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-01-02T19:48:34.409332Z","iopub.execute_input":"2024-01-02T19:48:34.410005Z","iopub.status.idle":"2024-01-02T19:48:34.419013Z","shell.execute_reply.started":"2024-01-02T19:48:34.409974Z","shell.execute_reply":"2024-01-02T19:48:34.417999Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# Training Loop\nepochs = 8\n\nfor epoch in range(epochs):\n    train(train_loader, model, loss_fn, optimizer, device, epoch)\n    scheduler.step()\n    \nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2024-01-02T19:48:38.543146Z","iopub.execute_input":"2024-01-02T19:48:38.543982Z","iopub.status.idle":"2024-01-02T19:55:41.604925Z","shell.execute_reply.started":"2024-01-02T19:48:38.543951Z","shell.execute_reply":"2024-01-02T19:55:41.604034Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"[1,     1] loss: 2.3288, Accuracy: 6.25%\n[1,   101] loss: 2.1852, Accuracy: 28.57%\n[1,   201] loss: 1.8436, Accuracy: 43.78%\n[1,   301] loss: 1.4701, Accuracy: 55.98%\n[1,   401] loss: 1.2134, Accuracy: 63.81%\n[1,   501] loss: 1.0320, Accuracy: 69.24%\n[1,   601] loss: 0.9009, Accuracy: 73.18%\nEnd of Epoch 1: Avg loss: 0.8423, Accuracy: 74.88%\n\n[2,     1] loss: 0.1735, Accuracy: 92.19%\n[2,   101] loss: 0.2120, Accuracy: 93.77%\n[2,   201] loss: 0.1959, Accuracy: 94.15%\n[2,   301] loss: 0.1824, Accuracy: 94.57%\n[2,   401] loss: 0.1777, Accuracy: 94.69%\n[2,   501] loss: 0.1707, Accuracy: 94.91%\n[2,   601] loss: 0.1655, Accuracy: 95.07%\nEnd of Epoch 2: Avg loss: 0.1625, Accuracy: 95.16%\n\n[3,     1] loss: 0.0726, Accuracy: 98.44%\n[3,   101] loss: 0.1230, Accuracy: 96.19%\n[3,   201] loss: 0.1205, Accuracy: 96.37%\n[3,   301] loss: 0.1213, Accuracy: 96.36%\n[3,   401] loss: 0.1182, Accuracy: 96.50%\n[3,   501] loss: 0.1151, Accuracy: 96.55%\n[3,   601] loss: 0.1115, Accuracy: 96.66%\nEnd of Epoch 3: Avg loss: 0.1110, Accuracy: 96.68%\n\n[4,     1] loss: 0.0807, Accuracy: 96.88%\n[4,   101] loss: 0.1021, Accuracy: 96.81%\n[4,   201] loss: 0.0949, Accuracy: 97.03%\n[4,   301] loss: 0.0952, Accuracy: 97.04%\n[4,   401] loss: 0.0945, Accuracy: 97.09%\n[4,   501] loss: 0.0934, Accuracy: 97.10%\n[4,   601] loss: 0.0924, Accuracy: 97.13%\nEnd of Epoch 4: Avg loss: 0.0910, Accuracy: 97.19%\n\n[5,     1] loss: 0.0766, Accuracy: 96.88%\n[5,   101] loss: 0.0873, Accuracy: 97.40%\n[5,   201] loss: 0.0837, Accuracy: 97.51%\n[5,   301] loss: 0.0800, Accuracy: 97.57%\n[5,   401] loss: 0.0798, Accuracy: 97.55%\n[5,   501] loss: 0.0792, Accuracy: 97.56%\n[5,   601] loss: 0.0807, Accuracy: 97.51%\nEnd of Epoch 5: Avg loss: 0.0797, Accuracy: 97.55%\n\n[6,     1] loss: 0.0265, Accuracy: 100.00%\n[6,   101] loss: 0.0656, Accuracy: 98.11%\n[6,   201] loss: 0.0703, Accuracy: 97.81%\n[6,   301] loss: 0.0714, Accuracy: 97.77%\n[6,   401] loss: 0.0718, Accuracy: 97.76%\n[6,   501] loss: 0.0728, Accuracy: 97.73%\n[6,   601] loss: 0.0706, Accuracy: 97.79%\nEnd of Epoch 6: Avg loss: 0.0700, Accuracy: 97.81%\n\n[7,     1] loss: 0.1762, Accuracy: 95.31%\n[7,   101] loss: 0.0716, Accuracy: 97.83%\n[7,   201] loss: 0.0683, Accuracy: 97.83%\n[7,   301] loss: 0.0668, Accuracy: 97.82%\n[7,   401] loss: 0.0659, Accuracy: 97.90%\n[7,   501] loss: 0.0637, Accuracy: 98.00%\n[7,   601] loss: 0.0648, Accuracy: 97.96%\nEnd of Epoch 7: Avg loss: 0.0641, Accuracy: 98.00%\n\n[8,     1] loss: 0.1726, Accuracy: 96.88%\n[8,   101] loss: 0.0633, Accuracy: 97.82%\n[8,   201] loss: 0.0635, Accuracy: 97.95%\n[8,   301] loss: 0.0609, Accuracy: 98.01%\n[8,   401] loss: 0.0607, Accuracy: 98.02%\n[8,   501] loss: 0.0590, Accuracy: 98.09%\n[8,   601] loss: 0.0584, Accuracy: 98.14%\nEnd of Epoch 8: Avg loss: 0.0583, Accuracy: 98.16%\n\nDone!\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()  # Set the model to evaluation mode\npredictions = []\n\nwith torch.no_grad():\n    for data in test_loader:\n        # Move input data to the same device as the model\n        data = data.to(device)\n\n        outputs = model(data)\n        _, predicted = torch.max(outputs.data, 1)\n        predictions.extend(predicted.cpu().tolist())  # Move predictions back to CPU\n\n# Create submission file\nsubmission = pd.DataFrame({\n    \"ImageId\": range(1, len(predictions) + 1),\n    \"Label\": predictions\n})\n\nsubmission.to_csv('predictions.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T19:57:04.004025Z","iopub.execute_input":"2024-01-02T19:57:04.004873Z","iopub.status.idle":"2024-01-02T19:57:04.987394Z","shell.execute_reply.started":"2024-01-02T19:57:04.004841Z","shell.execute_reply":"2024-01-02T19:57:04.986423Z"},"trusted":true},"execution_count":72,"outputs":[]}]}